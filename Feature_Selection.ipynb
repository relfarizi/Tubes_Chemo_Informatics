{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "colab": {
      "name": "Feature_Selection.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyWvMdBb5xhc",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6n0D9OuHO7f",
        "colab_type": "text"
      },
      "source": [
        "### Data test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EqT9gM1f9Q",
        "colab_type": "code",
        "outputId": "b67c45f3-f698-4a34-c4e5-03a31742ae5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "data_train = pd.read_csv(link+\"train.csv\")\n",
        "data_train_fitur = data_train.iloc[:,:34]\n",
        "data_train_label = data_train.iloc[:,34]\n",
        "feature = data_train_fitur.columns\n",
        "data_train.head(5)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ALogP</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>AATS6m</th>\n",
              "      <th>AATS8v</th>\n",
              "      <th>AATS8e</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS2s</th>\n",
              "      <th>AATS7s</th>\n",
              "      <th>AATS8s</th>\n",
              "      <th>ATSC1m</th>\n",
              "      <th>ATSC1i</th>\n",
              "      <th>ATSC3i</th>\n",
              "      <th>ATSC8i</th>\n",
              "      <th>AATSC0v</th>\n",
              "      <th>C1SP2</th>\n",
              "      <th>CrippenLogP</th>\n",
              "      <th>SaasC</th>\n",
              "      <th>SssNH</th>\n",
              "      <th>SdO</th>\n",
              "      <th>minHBa</th>\n",
              "      <th>maxaaN</th>\n",
              "      <th>MAXDN</th>\n",
              "      <th>MAXDP</th>\n",
              "      <th>ETA_dBeta</th>\n",
              "      <th>nHBDon</th>\n",
              "      <th>MIC2</th>\n",
              "      <th>ZMIC5</th>\n",
              "      <th>MDEC-33</th>\n",
              "      <th>MLFER_E</th>\n",
              "      <th>n6Ring</th>\n",
              "      <th>nHeteroRing</th>\n",
              "      <th>n6HeteroRing</th>\n",
              "      <th>SRW5</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.9195</td>\n",
              "      <td>2588.934432</td>\n",
              "      <td>48.158117</td>\n",
              "      <td>178.551366</td>\n",
              "      <td>7.519247</td>\n",
              "      <td>149.013676</td>\n",
              "      <td>161.485521</td>\n",
              "      <td>3.284722</td>\n",
              "      <td>3.060185</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>10.143350</td>\n",
              "      <td>-7.363836</td>\n",
              "      <td>-14.367302</td>\n",
              "      <td>3.665693</td>\n",
              "      <td>49.264888</td>\n",
              "      <td>2</td>\n",
              "      <td>1.88109</td>\n",
              "      <td>1.405937</td>\n",
              "      <td>2.970667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.970667</td>\n",
              "      <td>4.011032</td>\n",
              "      <td>1.884254</td>\n",
              "      <td>3.863775</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2</td>\n",
              "      <td>30.767343</td>\n",
              "      <td>24.812853</td>\n",
              "      <td>1.310371</td>\n",
              "      <td>1.985</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4614</td>\n",
              "      <td>5634.103006</td>\n",
              "      <td>94.201531</td>\n",
              "      <td>196.140696</td>\n",
              "      <td>7.581138</td>\n",
              "      <td>146.305448</td>\n",
              "      <td>158.591102</td>\n",
              "      <td>2.332989</td>\n",
              "      <td>1.925086</td>\n",
              "      <td>2.089559</td>\n",
              "      <td>227.694609</td>\n",
              "      <td>-5.871438</td>\n",
              "      <td>-44.012942</td>\n",
              "      <td>-14.913076</td>\n",
              "      <td>53.706977</td>\n",
              "      <td>4</td>\n",
              "      <td>5.08288</td>\n",
              "      <td>4.956805</td>\n",
              "      <td>3.627957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.105045</td>\n",
              "      <td>4.651758</td>\n",
              "      <td>1.753193</td>\n",
              "      <td>3.792565</td>\n",
              "      <td>-4.25</td>\n",
              "      <td>2</td>\n",
              "      <td>39.741788</td>\n",
              "      <td>28.585041</td>\n",
              "      <td>3.383162</td>\n",
              "      <td>2.060</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5112</td>\n",
              "      <td>2834.386834</td>\n",
              "      <td>42.637339</td>\n",
              "      <td>168.834145</td>\n",
              "      <td>7.509380</td>\n",
              "      <td>140.140072</td>\n",
              "      <td>148.667669</td>\n",
              "      <td>3.262452</td>\n",
              "      <td>3.059524</td>\n",
              "      <td>3.482759</td>\n",
              "      <td>15.993973</td>\n",
              "      <td>5.492679</td>\n",
              "      <td>-8.180366</td>\n",
              "      <td>-15.128616</td>\n",
              "      <td>52.604904</td>\n",
              "      <td>1</td>\n",
              "      <td>3.54059</td>\n",
              "      <td>5.969862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.018156</td>\n",
              "      <td>9.057510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.439388</td>\n",
              "      <td>4.018156</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1</td>\n",
              "      <td>32.621372</td>\n",
              "      <td>22.616729</td>\n",
              "      <td>8.250206</td>\n",
              "      <td>1.857</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.4450</td>\n",
              "      <td>5379.145233</td>\n",
              "      <td>39.184295</td>\n",
              "      <td>172.733317</td>\n",
              "      <td>7.712846</td>\n",
              "      <td>150.265098</td>\n",
              "      <td>164.092245</td>\n",
              "      <td>2.858286</td>\n",
              "      <td>2.398794</td>\n",
              "      <td>2.870885</td>\n",
              "      <td>138.131207</td>\n",
              "      <td>-39.512712</td>\n",
              "      <td>41.307650</td>\n",
              "      <td>21.492683</td>\n",
              "      <td>48.901921</td>\n",
              "      <td>4</td>\n",
              "      <td>4.99658</td>\n",
              "      <td>5.265771</td>\n",
              "      <td>3.283074</td>\n",
              "      <td>11.959264</td>\n",
              "      <td>1.716423</td>\n",
              "      <td>4.694590</td>\n",
              "      <td>2.280014</td>\n",
              "      <td>4.959264</td>\n",
              "      <td>-3.75</td>\n",
              "      <td>2</td>\n",
              "      <td>37.626171</td>\n",
              "      <td>29.787688</td>\n",
              "      <td>6.467895</td>\n",
              "      <td>3.576</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.5272</td>\n",
              "      <td>4699.962622</td>\n",
              "      <td>65.748944</td>\n",
              "      <td>205.559532</td>\n",
              "      <td>7.809137</td>\n",
              "      <td>151.119831</td>\n",
              "      <td>157.628443</td>\n",
              "      <td>4.743490</td>\n",
              "      <td>3.223584</td>\n",
              "      <td>3.759916</td>\n",
              "      <td>355.631532</td>\n",
              "      <td>14.764704</td>\n",
              "      <td>-16.529422</td>\n",
              "      <td>8.420096</td>\n",
              "      <td>48.287508</td>\n",
              "      <td>1</td>\n",
              "      <td>2.73038</td>\n",
              "      <td>4.061453</td>\n",
              "      <td>3.122178</td>\n",
              "      <td>22.734161</td>\n",
              "      <td>2.886149</td>\n",
              "      <td>4.232194</td>\n",
              "      <td>5.516957</td>\n",
              "      <td>4.367080</td>\n",
              "      <td>6.00</td>\n",
              "      <td>4</td>\n",
              "      <td>39.955030</td>\n",
              "      <td>30.249632</td>\n",
              "      <td>3.706843</td>\n",
              "      <td>3.322</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ALogP        ATS0m     AATS6m  ...  n6HeteroRing      SRW5  Label\n",
              "0 -0.9195  2588.934432  48.158117  ...           1.0  0.000000      0\n",
              "1  0.4614  5634.103006  94.201531  ...           0.0  3.044522      1\n",
              "2  0.5112  2834.386834  42.637339  ...           0.0  2.397895      0\n",
              "3 -1.4450  5379.145233  39.184295  ...           2.0  2.397895      1\n",
              "4 -2.5272  4699.962622  65.748944  ...           0.0  2.397895      1\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFFuuEBcHr0W",
        "colab_type": "text"
      },
      "source": [
        "### Data train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqv5jv5Y1f8V",
        "colab_type": "code",
        "outputId": "89c1ba4a-96fb-4d4f-c780-dd82e152e8c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "link =\"https://raw.githubusercontent.com/relfarizi/Tubes_Chemo_Informatics/master/Data/\"\n",
        "#link = \"Data/\"\n",
        "data_test = pd.read_csv(link+\"test.csv\")\n",
        "data_test_fitur = data_test.iloc[:,:34]\n",
        "data_test_label = data_test.iloc[:,34]\n",
        "data_test.head(5)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ALogP</th>\n",
              "      <th>ATS0m</th>\n",
              "      <th>AATS6m</th>\n",
              "      <th>AATS8v</th>\n",
              "      <th>AATS8e</th>\n",
              "      <th>AATS1i</th>\n",
              "      <th>AATS3i</th>\n",
              "      <th>AATS2s</th>\n",
              "      <th>AATS7s</th>\n",
              "      <th>AATS8s</th>\n",
              "      <th>ATSC1m</th>\n",
              "      <th>ATSC1i</th>\n",
              "      <th>ATSC3i</th>\n",
              "      <th>ATSC8i</th>\n",
              "      <th>AATSC0v</th>\n",
              "      <th>C1SP2</th>\n",
              "      <th>CrippenLogP</th>\n",
              "      <th>SaasC</th>\n",
              "      <th>SssNH</th>\n",
              "      <th>SdO</th>\n",
              "      <th>minHBa</th>\n",
              "      <th>maxaaN</th>\n",
              "      <th>MAXDN</th>\n",
              "      <th>MAXDP</th>\n",
              "      <th>ETA_dBeta</th>\n",
              "      <th>nHBDon</th>\n",
              "      <th>MIC2</th>\n",
              "      <th>ZMIC5</th>\n",
              "      <th>MDEC-33</th>\n",
              "      <th>MLFER_E</th>\n",
              "      <th>n6Ring</th>\n",
              "      <th>nHeteroRing</th>\n",
              "      <th>n6HeteroRing</th>\n",
              "      <th>SRW5</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6629</td>\n",
              "      <td>3600.454537</td>\n",
              "      <td>44.378864</td>\n",
              "      <td>90.232187</td>\n",
              "      <td>7.056266</td>\n",
              "      <td>143.816368</td>\n",
              "      <td>149.961105</td>\n",
              "      <td>2.213838</td>\n",
              "      <td>1.583039</td>\n",
              "      <td>1.456019</td>\n",
              "      <td>163.331784</td>\n",
              "      <td>-2.977714</td>\n",
              "      <td>-10.493268</td>\n",
              "      <td>-26.538061</td>\n",
              "      <td>55.411281</td>\n",
              "      <td>1</td>\n",
              "      <td>2.98231</td>\n",
              "      <td>4.589495</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.817910</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.466058</td>\n",
              "      <td>1.156626</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>37.802054</td>\n",
              "      <td>21.851175</td>\n",
              "      <td>10.879323</td>\n",
              "      <td>2.290</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.7616</td>\n",
              "      <td>3060.383420</td>\n",
              "      <td>34.874461</td>\n",
              "      <td>115.931991</td>\n",
              "      <td>7.295112</td>\n",
              "      <td>145.030976</td>\n",
              "      <td>154.041649</td>\n",
              "      <td>2.221871</td>\n",
              "      <td>2.351732</td>\n",
              "      <td>2.798780</td>\n",
              "      <td>100.945224</td>\n",
              "      <td>-4.755817</td>\n",
              "      <td>-15.515577</td>\n",
              "      <td>-3.993285</td>\n",
              "      <td>52.405008</td>\n",
              "      <td>1</td>\n",
              "      <td>3.03108</td>\n",
              "      <td>2.950855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.477130</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.817594</td>\n",
              "      <td>3.004613</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>35.482547</td>\n",
              "      <td>20.365592</td>\n",
              "      <td>9.646462</td>\n",
              "      <td>1.873</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5121</td>\n",
              "      <td>7331.436096</td>\n",
              "      <td>85.318863</td>\n",
              "      <td>213.989917</td>\n",
              "      <td>7.858608</td>\n",
              "      <td>149.499565</td>\n",
              "      <td>156.948782</td>\n",
              "      <td>2.744017</td>\n",
              "      <td>2.548596</td>\n",
              "      <td>2.556183</td>\n",
              "      <td>21.310284</td>\n",
              "      <td>18.241775</td>\n",
              "      <td>-8.374438</td>\n",
              "      <td>3.163052</td>\n",
              "      <td>50.509062</td>\n",
              "      <td>2</td>\n",
              "      <td>4.74698</td>\n",
              "      <td>7.882546</td>\n",
              "      <td>3.472342</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.431286</td>\n",
              "      <td>4.44074</td>\n",
              "      <td>2.079434</td>\n",
              "      <td>2.373667</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3</td>\n",
              "      <td>50.066343</td>\n",
              "      <td>28.691766</td>\n",
              "      <td>7.450309</td>\n",
              "      <td>3.679</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.044522</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.2529</td>\n",
              "      <td>4204.710985</td>\n",
              "      <td>82.695080</td>\n",
              "      <td>203.246422</td>\n",
              "      <td>7.869357</td>\n",
              "      <td>152.792389</td>\n",
              "      <td>160.368528</td>\n",
              "      <td>4.551913</td>\n",
              "      <td>3.432323</td>\n",
              "      <td>4.172222</td>\n",
              "      <td>79.589743</td>\n",
              "      <td>2.599222</td>\n",
              "      <td>-29.585872</td>\n",
              "      <td>-10.960972</td>\n",
              "      <td>40.961630</td>\n",
              "      <td>3</td>\n",
              "      <td>4.31267</td>\n",
              "      <td>2.599638</td>\n",
              "      <td>3.032796</td>\n",
              "      <td>10.701149</td>\n",
              "      <td>3.032796</td>\n",
              "      <td>4.48096</td>\n",
              "      <td>2.444328</td>\n",
              "      <td>3.701149</td>\n",
              "      <td>7.50</td>\n",
              "      <td>1</td>\n",
              "      <td>41.726760</td>\n",
              "      <td>30.059483</td>\n",
              "      <td>4.433632</td>\n",
              "      <td>3.659</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.397895</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.2762</td>\n",
              "      <td>5244.652878</td>\n",
              "      <td>82.312760</td>\n",
              "      <td>136.455622</td>\n",
              "      <td>7.899088</td>\n",
              "      <td>146.426895</td>\n",
              "      <td>159.287076</td>\n",
              "      <td>3.833240</td>\n",
              "      <td>4.070850</td>\n",
              "      <td>3.122699</td>\n",
              "      <td>-32.144412</td>\n",
              "      <td>-5.645679</td>\n",
              "      <td>11.847075</td>\n",
              "      <td>-2.098686</td>\n",
              "      <td>47.547545</td>\n",
              "      <td>1</td>\n",
              "      <td>2.73478</td>\n",
              "      <td>1.917956</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.418902</td>\n",
              "      <td>0.577550</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.973811</td>\n",
              "      <td>6.280024</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>45.255873</td>\n",
              "      <td>26.226152</td>\n",
              "      <td>11.051717</td>\n",
              "      <td>2.533</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ALogP        ATS0m     AATS6m  ...  n6HeteroRing      SRW5  Label\n",
              "0  0.6629  3600.454537  44.378864  ...           1.0  3.044522      0\n",
              "1 -0.7616  3060.383420  34.874461  ...           1.0  2.397895      0\n",
              "2  0.5121  7331.436096  85.318863  ...           0.0  3.044522      1\n",
              "3  0.2529  4204.710985  82.695080  ...           2.0  2.397895      1\n",
              "4 -0.2762  5244.652878  82.312760  ...           0.0  0.000000      0\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OcHMVl_1f91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train = data_train_fitur\n",
        "y_train = data_train_label\n",
        "X_test = data_test_fitur\n",
        "y_test = data_test_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHMvYrg_HGl1",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3qf0UdUH3AP",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGuE4k_91f-R",
        "colab_type": "code",
        "outputId": "607c9137-4e35-48af-b405-30602a7288ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf =(RandomForestClassifier(n_estimators = 100, verbose = 1))\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=1, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZZE7akkIBx-",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttO28B-9HGl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52353dd4-e5ad-4797-a496-754dd3297cd2"
      },
      "source": [
        "df_feature = pd.DataFrame( {\"feature\":feature, \"feature_importance\" :clf.feature_importances_})\n",
        "df_feature"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>feature_importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALogP</td>\n",
              "      <td>0.004707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ATS0m</td>\n",
              "      <td>0.061857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AATS6m</td>\n",
              "      <td>0.022481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AATS8v</td>\n",
              "      <td>0.060334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AATS8e</td>\n",
              "      <td>0.028656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AATS1i</td>\n",
              "      <td>0.025840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AATS3i</td>\n",
              "      <td>0.008549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AATS2s</td>\n",
              "      <td>0.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AATS7s</td>\n",
              "      <td>0.006091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AATS8s</td>\n",
              "      <td>0.013868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ATSC1m</td>\n",
              "      <td>0.008923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ATSC1i</td>\n",
              "      <td>0.007713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ATSC3i</td>\n",
              "      <td>0.005882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ATSC8i</td>\n",
              "      <td>0.005840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>AATSC0v</td>\n",
              "      <td>0.009032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>C1SP2</td>\n",
              "      <td>0.046907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CrippenLogP</td>\n",
              "      <td>0.009498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SaasC</td>\n",
              "      <td>0.007089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SssNH</td>\n",
              "      <td>0.063635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SdO</td>\n",
              "      <td>0.008630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>minHBa</td>\n",
              "      <td>0.010822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>maxaaN</td>\n",
              "      <td>0.082093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MAXDN</td>\n",
              "      <td>0.008165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>MAXDP</td>\n",
              "      <td>0.008263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ETA_dBeta</td>\n",
              "      <td>0.006097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>nHBDon</td>\n",
              "      <td>0.037944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>MIC2</td>\n",
              "      <td>0.124714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ZMIC5</td>\n",
              "      <td>0.023345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>MDEC-33</td>\n",
              "      <td>0.040792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>MLFER_E</td>\n",
              "      <td>0.175029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>n6Ring</td>\n",
              "      <td>0.006818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>nHeteroRing</td>\n",
              "      <td>0.042173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>n6HeteroRing</td>\n",
              "      <td>0.004214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>SRW5</td>\n",
              "      <td>0.019501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         feature  feature_importance\n",
              "0          ALogP            0.004707\n",
              "1          ATS0m            0.061857\n",
              "2         AATS6m            0.022481\n",
              "3         AATS8v            0.060334\n",
              "4         AATS8e            0.028656\n",
              "5         AATS1i            0.025840\n",
              "6         AATS3i            0.008549\n",
              "7         AATS2s            0.004500\n",
              "8         AATS7s            0.006091\n",
              "9         AATS8s            0.013868\n",
              "10        ATSC1m            0.008923\n",
              "11        ATSC1i            0.007713\n",
              "12        ATSC3i            0.005882\n",
              "13        ATSC8i            0.005840\n",
              "14       AATSC0v            0.009032\n",
              "15         C1SP2            0.046907\n",
              "16   CrippenLogP            0.009498\n",
              "17         SaasC            0.007089\n",
              "18         SssNH            0.063635\n",
              "19           SdO            0.008630\n",
              "20        minHBa            0.010822\n",
              "21        maxaaN            0.082093\n",
              "22         MAXDN            0.008165\n",
              "23         MAXDP            0.008263\n",
              "24     ETA_dBeta            0.006097\n",
              "25        nHBDon            0.037944\n",
              "26          MIC2            0.124714\n",
              "27         ZMIC5            0.023345\n",
              "28       MDEC-33            0.040792\n",
              "29       MLFER_E            0.175029\n",
              "30        n6Ring            0.006818\n",
              "31   nHeteroRing            0.042173\n",
              "32  n6HeteroRing            0.004214\n",
              "33          SRW5            0.019501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elg-IUMFHGl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "31939b19-029d-4e09-ccbf-c202f98bf1af"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_ = pd.Series(clf.feature_importances_, index=feature).sort_values(ascending=False)\n",
        "data_[:].plot(kind='bar', title='Feature Importance by Random Forest', figsize=(15,8))\n",
        "plt.ylabel('Feature Importance values')\n",
        "plt.subplots_adjust(bottom=0.25)\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-CPeghzINrb",
        "colab_type": "text"
      },
      "source": [
        "#### Feature Selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm60_vUT1f-k",
        "colab_type": "code",
        "outputId": "616df5bc-b352-425b-e9bf-41e0601524ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "feature_idx = sorted(range(len(clf.feature_importances_)), key=lambda k: clf.feature_importances_[k],reverse=True)\n",
        "n_feature = 5\n",
        "feature_selected = []\n",
        "for i in (feature_idx[:n_feature]) :\n",
        "    feature_selected.append(feature[i])\n",
        "\n",
        "feature_importance = []\n",
        "\n",
        "for x in zip(feature, clf.feature_importances_):\n",
        "    if x[0] in feature_selected :\n",
        "        feature_importance.append([x[0],x[1]])\n",
        "feature_importance"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ATS0m', 0.06185715129825578],\n",
              " ['SssNH', 0.06363457846894423],\n",
              " ['maxaaN', 0.0820929763028949],\n",
              " ['MIC2', 0.12471391769869342],\n",
              " ['MLFER_E', 0.1750291604593379]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prsJMWTvIVsH",
        "colab_type": "text"
      },
      "source": [
        "### Korelasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJzS_i5jHGmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "85f159be-1df6-4603-94a2-104df979b776"
      },
      "source": [
        "data = data_train.loc[:,[x for x in feature_selected]]\n",
        "correlation = data.corr()\n",
        "correlation"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLFER_E</th>\n",
              "      <th>MIC2</th>\n",
              "      <th>maxaaN</th>\n",
              "      <th>SssNH</th>\n",
              "      <th>ATS0m</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MLFER_E</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.638344</td>\n",
              "      <td>0.662881</td>\n",
              "      <td>0.588320</td>\n",
              "      <td>0.529192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIC2</th>\n",
              "      <td>0.638344</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.430950</td>\n",
              "      <td>0.406729</td>\n",
              "      <td>0.766824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maxaaN</th>\n",
              "      <td>0.662881</td>\n",
              "      <td>0.430950</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.466506</td>\n",
              "      <td>0.332049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SssNH</th>\n",
              "      <td>0.588320</td>\n",
              "      <td>0.406729</td>\n",
              "      <td>0.466506</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.399633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ATS0m</th>\n",
              "      <td>0.529192</td>\n",
              "      <td>0.766824</td>\n",
              "      <td>0.332049</td>\n",
              "      <td>0.399633</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          MLFER_E      MIC2    maxaaN     SssNH     ATS0m\n",
              "MLFER_E  1.000000  0.638344  0.662881  0.588320  0.529192\n",
              "MIC2     0.638344  1.000000  0.430950  0.406729  0.766824\n",
              "maxaaN   0.662881  0.430950  1.000000  0.466506  0.332049\n",
              "SssNH    0.588320  0.406729  0.466506  1.000000  0.399633\n",
              "ATS0m    0.529192  0.766824  0.332049  0.399633  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyPMDOaM7Y-f",
        "colab_type": "code",
        "outputId": "c05bd3ad-a1af-48d6-d127-2ab1507becaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "f,ax = plt.subplots(figsize=(15,10))\n",
        "sns.heatmap(correlation, annot=True, linewidths=.5, fmt='.2f', ax=ax)\n",
        "plt.show"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM_DvciQIbWE",
        "colab_type": "text"
      },
      "source": [
        "### Data by Feature Selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27nkbjEn1f_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_important_train = data_train_fitur.loc[:,feature_selected]\n",
        "y_train = data_train_label\n",
        "X_important_test = data_test_fitur.loc[:,feature_selected]\n",
        "y_test = data_test_label\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnsakFprHGmQ",
        "colab_type": "text"
      },
      "source": [
        "## Model Prediksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYZCJ8qvJZSm",
        "colab_type": "text"
      },
      "source": [
        "### Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyi9NQk8HGmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "f2c546aa-8e52-4fec-e8e7-fa23ed0886dc"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Parameter yang akan digunakan \n",
        "\n",
        "params = {\n",
        "          \"n_estimators\" : [2,10],\n",
        "          \"max_depth\" : [1,10],\n",
        "          \"learning_rate\" :[0.1,0.3]\n",
        "          }\n",
        "\n",
        "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "\n",
        "print(params)\n",
        "print(cv)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [2, 10], 'max_depth': [1, 10], 'learning_rate': [0.01, 0.3]}\n",
            "KFold(n_splits=10, random_state=42, shuffle=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLw6I-zHIp7S",
        "colab_type": "text"
      },
      "source": [
        "### Uji Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNneUrUJIqyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f8478f1-ef57-4711-a52d-145f07f7ca4a"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "for i in range(2) :\n",
        "    model = XGBClassifier(n_estimators = params[\"n_estimators\"][i], max_depth = params[\"max_depth\"][i], learning_rate = params[\"learning_rate\"][i])\n",
        "    model.fit(X_important_train,y_train)\n",
        "    y_pred_train = model.predict(X_important_train)\n",
        "    score = cross_val_score(clf, X_important_train, y_train, cv=cv,verbose=0)\n",
        "    acc_train.append(score.mean())\n",
        "    #print(len(X_important_test))\n",
        "    y_p =model.predict(X_important_test)\n",
        "    print(len(y_test))\n",
        "    print(accuracy_score(y_p,y_test))\n",
        "    acc_test.append(accuracy_score(y_p,y_test))\n",
        "    #print(score.mean())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "697\n",
            "0.9053084648493543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "697\n",
            "0.9512195121951219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Watv9FhJd1W",
        "colab_type": "text"
      },
      "source": [
        "### Hasil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54TXitMjHGmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "f9566471-2585-4b6a-915c-4416cc34f116"
      },
      "source": [
        "print(acc_train)\n",
        "for i in range(2) :\n",
        "    print(\"Parameter\")\n",
        "    for x in params.keys():\n",
        "        print(x,\"=\",params[x][i])\n",
        "    print(\"akurasi train\",i+1,\"= \", acc_train[i])\n",
        "    print(\"akurasi test\",i+1,\"= \", acc_test[i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.9581913201545103, 0.9588010300689238]\n",
            "Parameter\n",
            "n_estimators = 2\n",
            "max_depth = 1\n",
            "learning_rate = 0.01\n",
            "akurasi train 1 =  0.9581913201545103\n",
            "akurasi test 1 =  0.9053084648493543\n",
            "\n",
            "\n",
            "Parameter\n",
            "n_estimators = 10\n",
            "max_depth = 10\n",
            "learning_rate = 0.3\n",
            "akurasi train 2 =  0.9588010300689238\n",
            "akurasi test 2 =  0.9512195121951219\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PzyXJtfHGmZ",
        "colab_type": "text"
      },
      "source": [
        "## Extended Version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjJJlK-NJoPf",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUlWZeAWJ1Wb",
        "colab_type": "text"
      },
      "source": [
        "#### Randomize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4LjX-jPHGmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "9ebbf814-4892-4ed3-b546-0469c322c551"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "\n",
        "parameters = {\"learning_rate\": [0.1, 0.01, 0.001, 0.2, 0.3 , 0.4 , 0.5],\n",
        "               #\"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
        "               \"max_depth\": [2, 4, 7, 10, 16],\n",
        "               \"n_estimators\": [100, 250, 500, 1000]}\n",
        "\n",
        "# Create RandomizedSearchCV Object\n",
        "model = XGBClassifier()\n",
        "xgb_rscv = RandomizedSearchCV(model, param_distributions = parameters, scoring = \"accuracy\",\n",
        "                             cv = cv, verbose = 0, random_state = 40)\n",
        "\n",
        "# Fit the model\n",
        "model_xgboost = xgb_rscv.fit(X_train_k, y_train_k)\n",
        "print(model_xgboost.best_params_)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': 250, 'max_depth': 2, 'learning_rate': 0.2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtNzW9BuKR77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4737a569-d097-4965-c87a-4c85ae42fec6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=42, shuffle=False)\n",
        "\n",
        "X = X_important_train\n",
        "y = y_train\n",
        "print(X.shape)\n",
        "#print(y_train)\n",
        "#print(y.shape)\n",
        "sc = []\n",
        "for train_index, test_index in cv.split(X):\n",
        "    X_test_k, y_test_k = X.iloc[test_index,:] , y.iloc[test_index]\n",
        "    X_train_k, y_train_k = X.iloc[train_index,:] , y.iloc[train_index]\n",
        "    model.fit(X_train_k,y_train_k)\n",
        "    y_pred_k = model.predict(X_test_k)\n",
        "    sc.append(accuracy_score(y_pred_k,y_test_k))\n",
        "    print(\"akurasi test = \", accuracy_score(y_pred_k,y_test_k))\n",
        "print(np.mean(sc))\n",
        "scor = cross_val_score(model,X,y,cv=cv)\n",
        "print(scor.mean())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1626, 5)\n",
            "akurasi test =  0.9539877300613497\n",
            "akurasi test =  0.96\n",
            "akurasi test =  0.9507692307692308\n",
            "akurasi test =  0.9538461538461539\n",
            "akurasi test =  0.963076923076923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-064db57f722f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"akurasi test = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mscor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbxKf3QdHGma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(n_estimators = 10)\n",
        "model.fit(X_important_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJCX9P_UHGmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "y_pred_train = model.predict(X_important_train)\n",
        "score = cross_val_score(clf, X_important_train, y_train, cv=5)\n",
        "\n",
        "y_pred_test = model.predict(X_important_test)\n",
        "print(accuracy_score(y_pred_test,y_test))\n",
        "print(score.mean())\n",
        " \n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG7YYdbKHGmk",
        "colab_type": "code",
        "colab": {},
        "outputId": "4bbc3e5d-a114-4ba6-b4dc-d5314e71ffc3"
      },
      "source": [
        "print(len(y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBHKK_37HGmo",
        "colab_type": "code",
        "colab": {},
        "outputId": "6434f877-60d0-4962-abff-a555ebf8e18f"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits=5, random_state=42, shuffle=False)\n",
        "print(type(y_train))\n",
        "\n",
        "X = X_important_train\n",
        "y = y_train\n",
        "print(X.shape)\n",
        "#print(y_train)\n",
        "#print(y.shape)\n",
        "sc = []\n",
        "for train_index, test_index in cv.split(X):\n",
        "    X_test_k, y_test_k = X.iloc[test_index,:] , y.iloc[test_index]\n",
        "    X_train_k, y_train_k = X.iloc[train_index,:] , y.iloc[train_index]\n",
        "    model.fit(X_train_k,y_train_k)\n",
        "    y_pred_k = model.predict(X_test_k)\n",
        "    sc.append(accuracy_score(y_pred_k,y_test_k))\n",
        "    print(\"akurasi test = \", accuracy_score(y_pred_k,y_test_k))\n",
        "print(np.mean(sc))\n",
        "scor = cross_val_score(model,X,y,cv=cv)\n",
        "print(scor.mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(1626, 6)\n",
            "akurasi test =  0.8220858895705522\n",
            "akurasi test = 0.7938461538461539\n",
            "akurasi test =  0.8615384615384616\n",
            "akurasi test =  0.8307692307692308\n",
            "akurasi test =  0.8215384615384616\n",
            "0.825955639452572\n",
            "0.825955639452572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnvkV0rOHGms",
        "colab_type": "code",
        "colab": {},
        "outputId": "6258cdd9-92b6-44bc-e181-3b9f9d36a6fe"
      },
      "source": [
        "print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqQvFsadHGmw",
        "colab_type": "code",
        "colab": {},
        "outputId": "3b4fbf27-8c0b-4995-86b0-378ed9efb392"
      },
      "source": [
        "print(model_xgboost.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdC-rm6QHGm2",
        "colab_type": "code",
        "colab": {},
        "outputId": "63eeba2b-3508-4bd9-a088-4feceb875cff"
      },
      "source": [
        "\"\"\"cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "\n",
        "params = {\"learning_rate\": [0.1, 0.2, 0.3 , 0.4 , 0.5],\n",
        "               #\"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
        "               \"max_depth\": [2, 4, 7, 10, 16],\n",
        "               \"n_estimators\": [10,100, 250, 500, 1000]}\n",
        "best_params = []\n",
        "for i in range(5):\n",
        "    model = XGBClassifier(n_estimators = params[\"n_estimators\"][i], max_depth = params[\"max_depth\"][i], learning_rate = params[\"learning_rate\"][i])\n",
        "    model.fit(X_important_train,y_train)\n",
        "    score = cross_val_score(model,X_important_train,y_train,cv=cv)\n",
        "    best_params.append([])\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cv = KFold(n_splits=10, random_state=42, shuffle=False)\\n\\nparams = {\"learning_rate\": [0.1, 0.2, 0.3 , 0.4 , 0.5],\\n               #\"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\\n               \"max_depth\": [2, 4, 7, 10, 16],\\n               \"n_estimators\": [10,100, 250, 500, 1000]}\\nbest_params = []\\nfor i in range(5):\\n    model = XGBClassifier(n_estimators = params[\"n_estimators\"][i], max_depth = params[\"max_depth\"][i], learning_rate = params[\"learning_rate\"][i])\\n    model.fit(X_important_train,y_train)\\n    score = cross_val_score(model,X_important_train,y_train,cv=cv)\\n    best_params.append([])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4l5fFRDHGm5",
        "colab_type": "code",
        "colab": {},
        "outputId": "d5f2556e-1cc0-4e44-a7de-484edc233344"
      },
      "source": [
        "y_pred_train = clf_important.predict(X_important_train)\n",
        "accuracy_score(y_train, y_pred_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR6uGBZa1f_q",
        "colab_type": "code",
        "outputId": "a32c90d2-dcea-457f-d4ef-f8fec9932dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
        "clf_important.fit(X_important_train, y_train)\n",
        "y_pred = clf_important.predict(X_important_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8522238163558106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "IM5wRbyzHGm_",
        "colab_type": "code",
        "colab": {},
        "outputId": "da694db7-cd77-4f6f-dda6-3f0636c847aa"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "X = X_important_train.to_numpy()\n",
        "X = np.array(X)\n",
        "y = y_train\n",
        "y = np.array(y)\n",
        "print(X)\n",
        "for i_train, j_test in cv.split(X):\n",
        "    train_index = []\n",
        "    test_index = []\n",
        "\n",
        "    for i in i_train :\n",
        "        train_index.append(i)\n",
        "    for i in j_test :\n",
        "        test_index.append(i)\n",
        "        \n",
        "    print(\"Train Index: \", train_index, \"\\n\")\n",
        "    print(\"Test Index: \", test_index)\n",
        "    print(len(train_index))\n",
        "    #X_train,y_train = X[train_index],y[train_index]\n",
        "    X_Test , y_test = X[test_index],y[test_index]\n",
        "    print(X_train)\n",
        "    #model.fit(X_train, y_train)\n",
        "    #y_pred = model.predict(X_test)\n",
        "    #scores.append(accuracy_score(y_pred,y_test))\n",
        "#print(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "08, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625] \n",
            "\n",
            "Test Index:  [1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463]\n",
            "1464\n",
            "       ALogP         ATS0m     AATS6m      AATS8v    AATS8e      AATS1i  \\\n",
            "0    -0.9195   2588.934432  48.158117  178.551366  7.519247  149.013676   \n",
            "1     0.4614   5634.103006  94.201531  196.140696  7.581138  146.305448   \n",
            "2     0.5112   2834.386834  42.637339  168.834145  7.509380  140.140072   \n",
            "3    -1.4450   5379.145233  39.184295  172.733317  7.712846  150.265098   \n",
            "4    -2.5272   4699.962622  65.748944  205.559532  7.809137  151.119831   \n",
            "...      ...           ...        ...         ...       ...         ...   \n",
            "1621  0.5317   6538.883379  73.059980  171.734927  7.735404  145.913746   \n",
            "1622 -2.7617   3733.568143  45.776943  121.335394  7.225093  146.094410   \n",
            "1623 -1.9360   2312.665429  55.352296   84.489903  8.875008  156.331998   \n",
            "1624  0.5327  11563.534144  75.799339  177.333851  7.557782  148.609720   \n",
            "1625  0.7261   4047.640877  82.294693  124.140446  8.055580  146.326666   \n",
            "\n",
            "          AATS3i    AATS2s     AATS7s    AATS8s  ...  ETA_dBeta  nHBDon  \\\n",
            "0     161.485521  3.284722   3.060185  2.833333  ...       2.25       2   \n",
            "1     158.591102  2.332989   1.925086  2.089559  ...      -4.25       2   \n",
            "2     148.667669  3.262452   3.059524  3.482759  ...       3.00       1   \n",
            "3     164.092245  2.858286   2.398794  2.870885  ...      -3.75       2   \n",
            "4     157.628443  4.743490   3.223584  3.759916  ...       6.00       4   \n",
            "...          ...       ...        ...       ...  ...        ...     ...   \n",
            "1621  160.050733  3.770138   3.360889  3.306493  ...       1.75       1   \n",
            "1622  157.964277  2.460259   2.165450  1.798122  ...      -7.00       1   \n",
            "1623  167.053605  5.068966  12.950000  6.500000  ...       2.00       1   \n",
            "1624  157.581175  2.932039   3.048591  2.701007  ...       1.50       2   \n",
            "1625  154.860488  3.980869   3.732419  3.509184  ...       3.25       2   \n",
            "\n",
            "           MIC2      ZMIC5   MDEC-33  MLFER_E  n6Ring  nHeteroRing  \\\n",
            "0     30.767343  24.812853  1.310371    1.985     2.0          1.0   \n",
            "1     39.741788  28.585041  3.383162    2.060     1.0          2.0   \n",
            "2     32.621372  22.616729  8.250206    1.857     2.0          0.0   \n",
            "3     37.626171  29.787688  6.467895    3.576     3.0          3.0   \n",
            "4     39.955030  30.249632  3.706843    3.322     2.0          1.0   \n",
            "...         ...        ...       ...      ...     ...          ...   \n",
            "1621  47.157151  26.789769  8.969086    3.474     3.0          2.0   \n",
            "1622  31.040645  27.208856  2.381102    1.055     1.0          1.0   \n",
            "1623  39.555130  21.159591  1.105209    1.140     1.0          1.0   \n",
            "1624  46.511076  31.522392  5.511349    3.332     3.0          1.0   \n",
            "1625  43.329163  23.295470  6.120464    2.098     2.0          1.0   \n",
            "\n",
            "      n6HeteroRing      SRW5  \n",
            "0              1.0  0.000000  \n",
            "1              0.0  3.044522  \n",
            "2              0.0  2.397895  \n",
            "3              2.0  2.397895  \n",
            "4              0.0  2.397895  \n",
            "...            ...       ...  \n",
            "1621           1.0  2.397895  \n",
            "1622           0.0  3.044522  \n",
            "1623           1.0  0.000000  \n",
            "1624           1.0  0.000000  \n",
            "1625           1.0  0.000000  \n",
            "\n",
            "[1626 rows x 34 columns]\n",
            "Train Index:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463] \n",
            "\n",
            "Test Index:  [1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625]\n",
            "1464\n",
            "       ALogP         ATS0m     AATS6m      AATS8v    AATS8e      AATS1i  \\\n",
            "0    -0.9195   2588.934432  48.158117  178.551366  7.519247  149.013676   \n",
            "1     0.4614   5634.103006  94.201531  196.140696  7.581138  146.305448   \n",
            "2     0.5112   2834.386834  42.637339  168.834145  7.509380  140.140072   \n",
            "3    -1.4450   5379.145233  39.184295  172.733317  7.712846  150.265098   \n",
            "4    -2.5272   4699.962622  65.748944  205.559532  7.809137  151.119831   \n",
            "...      ...           ...        ...         ...       ...         ...   \n",
            "1621  0.5317   6538.883379  73.059980  171.734927  7.735404  145.913746   \n",
            "1622 -2.7617   3733.568143  45.776943  121.335394  7.225093  146.094410   \n",
            "1623 -1.9360   2312.665429  55.352296   84.489903  8.875008  156.331998   \n",
            "1624  0.5327  11563.534144  75.799339  177.333851  7.557782  148.609720   \n",
            "1625  0.7261   4047.640877  82.294693  124.140446  8.055580  146.326666   \n",
            "\n",
            "          AATS3i    AATS2s     AATS7s    AATS8s  ...  ETA_dBeta  nHBDon  \\\n",
            "0     161.485521  3.284722   3.060185  2.833333  ...       2.25       2   \n",
            "1     158.591102  2.332989   1.925086  2.089559  ...      -4.25       2   \n",
            "2     148.667669  3.262452   3.059524  3.482759  ...       3.00       1   \n",
            "3     164.092245  2.858286   2.398794  2.870885  ...      -3.75       2   \n",
            "4     157.628443  4.743490   3.223584  3.759916  ...       6.00       4   \n",
            "...          ...       ...        ...       ...  ...        ...     ...   \n",
            "1621  160.050733  3.770138   3.360889  3.306493  ...       1.75       1   \n",
            "1622  157.964277  2.460259   2.165450  1.798122  ...      -7.00       1   \n",
            "1623  167.053605  5.068966  12.950000  6.500000  ...       2.00       1   \n",
            "1624  157.581175  2.932039   3.048591  2.701007  ...       1.50       2   \n",
            "1625  154.860488  3.980869   3.732419  3.509184  ...       3.25       2   \n",
            "\n",
            "           MIC2      ZMIC5   MDEC-33  MLFER_E  n6Ring  nHeteroRing  \\\n",
            "0     30.767343  24.812853  1.310371    1.985     2.0          1.0   \n",
            "1     39.741788  28.585041  3.383162    2.060     1.0          2.0   \n",
            "2     32.621372  22.616729  8.250206    1.857     2.0          0.0   \n",
            "3     37.626171  29.787688  6.467895    3.576     3.0          3.0   \n",
            "4     39.955030  30.249632  3.706843    3.322     2.0          1.0   \n",
            "...         ...        ...       ...      ...     ...          ...   \n",
            "1621  47.157151  26.789769  8.969086    3.474     3.0          2.0   \n",
            "1622  31.040645  27.208856  2.381102    1.055     1.0          1.0   \n",
            "1623  39.555130  21.159591  1.105209    1.140     1.0          1.0   \n",
            "1624  46.511076  31.522392  5.511349    3.332     3.0          1.0   \n",
            "1625  43.329163  23.295470  6.120464    2.098     2.0          1.0   \n",
            "\n",
            "      n6HeteroRing      SRW5  \n",
            "0              1.0  0.000000  \n",
            "1              0.0  3.044522  \n",
            "2              0.0  2.397895  \n",
            "3              2.0  2.397895  \n",
            "4              0.0  2.397895  \n",
            "...            ...       ...  \n",
            "1621           1.0  2.397895  \n",
            "1622           0.0  3.044522  \n",
            "1623           1.0  0.000000  \n",
            "1624           1.0  0.000000  \n",
            "1625           1.0  0.000000  \n",
            "\n",
            "[1626 rows x 34 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETBSgLb6HGnB",
        "colab_type": "code",
        "colab": {},
        "outputId": "67c75569-9b39-4cbf-e71c-4b4fa0be1fab"
      },
      "source": [
        "list_a = [0,1,2,3,4,5]\n",
        "\n",
        "list_a[-3:-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLIAIRnsHGnE",
        "colab_type": "code",
        "colab": {},
        "outputId": "376074c6-cf3f-4016-bd69-702b726157d2"
      },
      "source": [
        "cv = KFold(n_splits=10, random_state=42, shuffle=False)\n",
        "print(cv)\n",
        "k_fold = 4\n",
        "train_fitur = data_train_fitur.loc[:20,feature_selected] \n",
        "train_label = y_train\n",
        "#print(train_label.iloc[:].shape)\n",
        "\n",
        "n_data = train_fitur.loc[:20,:].shape[0]\n",
        "start = 0\n",
        "step = n_data//k_fold\n",
        "end = step\n",
        "#print(end)\n",
        "for i in range(k_fold) :\n",
        "    X_test, y_test = train_fitur.loc[start:end,feature_selected] , train_fitur.iloc[start:end]\n",
        "    X_train, y_train = train_fitur.loc[end:,feature_selected] , train_fitur.iloc[end:]\n",
        "    print(start,end)\n",
        "    start = end\n",
        "    end = start + step\n",
        "    print(\"K\",i)    \n",
        "    print(y_test)    \n",
        "    print(y_train)\n",
        "    #print(len(X_test),len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=10, random_state=42, shuffle=False)\n",
            "0 5\n",
            "K 0\n",
            "      ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "0   3.665693           1.0 -0.9195   10.143350  3.060185\n",
            "1 -14.913076           0.0  0.4614  227.694609  1.925086\n",
            "2 -15.128616           0.0  0.5112   15.993973  3.059524\n",
            "3  21.492683           2.0 -1.4450  138.131207  2.398794\n",
            "4   8.420096           0.0 -2.5272  355.631532  3.223584\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "5    1.648183           1.0 -0.8845  218.276296  2.968450\n",
            "6   25.722061           1.0 -0.6824  110.083927  2.214815\n",
            "7    7.967441           0.0 -0.7282  -32.406581  3.743590\n",
            "8   19.871346           0.0  0.4224   78.552543  3.626503\n",
            "9  -11.016873           1.0 -1.2126   24.798538  4.031963\n",
            "10   5.020188           0.0 -2.2514  371.125888  3.937483\n",
            "11 -13.121557           0.0  0.3519   -9.461032  3.583333\n",
            "12  -3.908630           0.0  0.5380  -66.507820  3.295086\n",
            "13  -4.922489           0.0  1.1303   46.511581  1.948948\n",
            "14  -2.052518           2.0 -0.3725   62.920677  3.215933\n",
            "15   5.423139           2.0  0.8284   41.642312  3.539988\n",
            "16 -16.487490           1.0 -1.2367   87.121599  2.904284\n",
            "17  17.168770           0.0  1.2103  480.443371  3.470576\n",
            "18  -3.349576           0.0 -1.1091   48.860789  2.677885\n",
            "19   0.000000           0.0 -1.2795   61.542775  1.000000\n",
            "20 -18.155247           1.0 -1.2755  131.446832  1.959350\n",
            "5 10\n",
            "K 1\n",
            "      ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "5   1.648183           1.0 -0.8845  218.276296  2.968450\n",
            "6  25.722061           1.0 -0.6824  110.083927  2.214815\n",
            "7   7.967441           0.0 -0.7282  -32.406581  3.743590\n",
            "8  19.871346           0.0  0.4224   78.552543  3.626503\n",
            "9 -11.016873           1.0 -1.2126   24.798538  4.031963\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "10   5.020188           0.0 -2.2514  371.125888  3.937483\n",
            "11 -13.121557           0.0  0.3519   -9.461032  3.583333\n",
            "12  -3.908630           0.0  0.5380  -66.507820  3.295086\n",
            "13  -4.922489           0.0  1.1303   46.511581  1.948948\n",
            "14  -2.052518           2.0 -0.3725   62.920677  3.215933\n",
            "15   5.423139           2.0  0.8284   41.642312  3.539988\n",
            "16 -16.487490           1.0 -1.2367   87.121599  2.904284\n",
            "17  17.168770           0.0  1.2103  480.443371  3.470576\n",
            "18  -3.349576           0.0 -1.1091   48.860789  2.677885\n",
            "19   0.000000           0.0 -1.2795   61.542775  1.000000\n",
            "20 -18.155247           1.0 -1.2755  131.446832  1.959350\n",
            "10 15\n",
            "K 2\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "10   5.020188           0.0 -2.2514  371.125888  3.937483\n",
            "11 -13.121557           0.0  0.3519   -9.461032  3.583333\n",
            "12  -3.908630           0.0  0.5380  -66.507820  3.295086\n",
            "13  -4.922489           0.0  1.1303   46.511581  1.948948\n",
            "14  -2.052518           2.0 -0.3725   62.920677  3.215933\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "15   5.423139           2.0  0.8284   41.642312  3.539988\n",
            "16 -16.487490           1.0 -1.2367   87.121599  2.904284\n",
            "17  17.168770           0.0  1.2103  480.443371  3.470576\n",
            "18  -3.349576           0.0 -1.1091   48.860789  2.677885\n",
            "19   0.000000           0.0 -1.2795   61.542775  1.000000\n",
            "20 -18.155247           1.0 -1.2755  131.446832  1.959350\n",
            "15 20\n",
            "K 3\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m    AATS7s\n",
            "15   5.423139           2.0  0.8284   41.642312  3.539988\n",
            "16 -16.487490           1.0 -1.2367   87.121599  2.904284\n",
            "17  17.168770           0.0  1.2103  480.443371  3.470576\n",
            "18  -3.349576           0.0 -1.1091   48.860789  2.677885\n",
            "19   0.000000           0.0 -1.2795   61.542775  1.000000\n",
            "       ATSC8i  n6HeteroRing   ALogP      ATSC1m   AATS7s\n",
            "20 -18.155247           1.0 -1.2755  131.446832  1.95935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXbuG32E1f_G",
        "colab_type": "code",
        "outputId": "c725212a-699a-40fe-f90d-61f3c89b9624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "sfm = SelectFromModel(clf, threshold=0.015)\n",
        "# Train the selector\n",
        "sfm.fit(X_train, y_train)\n",
        "len(sfm.get_support())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftMeaHPO1f_T",
        "colab_type": "code",
        "outputId": "bca905f7-22f9-4a6f-e05b-e29d8d979cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "\"\"\"feature_selected = []\n",
        "for feature_list_index in sfm.get_support(indices=True):\n",
        "    #print(feature_list_index)\n",
        "    #print(feature[feature_list_index])\n",
        "    feature_selected.append(feature[feature_list_index])\"\"\"\n",
        "\n",
        "data = data_train.loc[:,[x for x in feature_selected]]\n",
        "correlation = data.corr()\n",
        "correlation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              n6HeteroRing    ATSC8i    AATS2s    AATS7s    ATSC1i\n",
              "n6HeteroRing      1.000000  0.067470 -0.158656 -0.077016 -0.633957\n",
              "ATSC8i            0.067470  1.000000  0.145636  0.101113 -0.177527\n",
              "AATS2s           -0.158656  0.145636  1.000000  0.698409  0.202387\n",
              "AATS7s           -0.077016  0.101113  0.698409  1.000000  0.152548\n",
              "ATSC1i           -0.633957 -0.177527  0.202387  0.152548  1.000000"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n6HeteroRing</th>\n",
              "      <th>ATSC8i</th>\n",
              "      <th>AATS2s</th>\n",
              "      <th>AATS7s</th>\n",
              "      <th>ATSC1i</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n6HeteroRing</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.067470</td>\n",
              "      <td>-0.158656</td>\n",
              "      <td>-0.077016</td>\n",
              "      <td>-0.633957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ATSC8i</th>\n",
              "      <td>0.067470</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.145636</td>\n",
              "      <td>0.101113</td>\n",
              "      <td>-0.177527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AATS2s</th>\n",
              "      <td>-0.158656</td>\n",
              "      <td>0.145636</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.698409</td>\n",
              "      <td>0.202387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AATS7s</th>\n",
              "      <td>-0.077016</td>\n",
              "      <td>0.101113</td>\n",
              "      <td>0.698409</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.152548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ATSC1i</th>\n",
              "      <td>-0.633957</td>\n",
              "      <td>-0.177527</td>\n",
              "      <td>0.202387</td>\n",
              "      <td>0.152548</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY_vFmf51f_z",
        "colab_type": "code",
        "outputId": "9d418149-0d0b-4988-d0ad-7eeb8fd4e3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_important_pred = clf_important.predict(X_important_train)\n",
        "#print(X_important_train)\n",
        "accuracy_score(y_train, y_important_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.58893443e+03 4.81581174e+01 1.78551366e+02 ... 1.31037070e+00\n",
            "  1.98500000e+00 1.00000000e+00]\n",
            " [5.63410301e+03 9.42015312e+01 1.96140696e+02 ... 3.38316237e+00\n",
            "  2.06000000e+00 2.00000000e+00]\n",
            " [2.83438683e+03 4.26373393e+01 1.68834145e+02 ... 8.25020562e+00\n",
            "  1.85700000e+00 0.00000000e+00]\n",
            " ...\n",
            " [2.31266543e+03 5.53522955e+01 8.44899028e+01 ... 1.10520945e+00\n",
            "  1.14000000e+00 1.00000000e+00]\n",
            " [1.15635341e+04 7.57993393e+01 1.77333851e+02 ... 5.51134881e+00\n",
            "  3.33200000e+00 1.00000000e+00]\n",
            " [4.04764088e+03 8.22946928e+01 1.24140446e+02 ... 6.12046394e+00\n",
            "  2.09800000e+00 1.00000000e+00]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1QyqZ5a1f_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_important_train = sfm.transform(X_train)\n",
        "X_important_test = sfm.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpIcbV8H_J2B",
        "colab_type": "code",
        "outputId": "78828e83-d787-49b1-c805-d57979085776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "def predict(X,y) :\n",
        "    y_pred_test_model_1 = model_1.predict(X)\n",
        "    con_matrix = confusion_matrix(y_pred_test_model_1, y)\n",
        "    accuracy = accuracy_score(y_pred_test_model_1,y)\n",
        "    tp, fp, fn, tn = con_matrix.ravel()\n",
        "    print(con_matrix)\n",
        "    print(tp, fp, fn, tn)\n",
        "    precision = tp/(tp+fp)\n",
        "    print(\"precision = \", precision)\n",
        "    recall = tp/(tp+fn)\n",
        "    print(\"recall = \", recall)\n",
        "    f1 = (2*recall*precision)/(recall+precision)\n",
        "    print(\"f1 = \",f1)\n",
        "    result = {\"matrix\":con_matrix,\"precision\":precision,\"recall\":recall,\"f1\":f1,\"accuracy\":accuracy}\n",
        "    return result\n",
        "\n",
        "predict(X_important_test,y_test)[\"matrix\"]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[335  13]\n",
            " [ 10 339]]\n",
            "335 13 10 339\n",
            "precision =  0.9626436781609196\n",
            "recall =  0.9710144927536232\n",
            "f1 =  0.9668109668109667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[335,  13],\n",
              "       [ 10, 339]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYdwx6Iu1f_4",
        "colab_type": "code",
        "outputId": "4f698c5a-00cc-43e9-f2f2-116203a898e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model_1 = XGBClassifier()\n",
        "\n",
        "model_1.fit(X_important_train,y_train)\n",
        "\n",
        "y_pred_train_model_1 = model_1.predict(X_important_train)\n",
        "\n",
        "accuracy_score(y_pred_train_model_1,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL_A0aCNHGnY",
        "colab_type": "code",
        "colab": {},
        "outputId": "22c62243-035b-4ad0-c472-70aa1f68a946"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "n_model = 2\n",
        "tuning = {\"learning_rate\" : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\n",
        "        \"max_depth\" : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        "        \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        "        \"gamma\" : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        "        \"colsample_bytree\": [ 0.3, 0.4, 0.5 , 0.7 ]\n",
        "}\n",
        "\n",
        "#print(tuning)\n",
        "pred= []\n",
        "\"\"\"\n",
        "for i in range(n_model) :\n",
        "    model = XGBClassifier(n_estimators = tuning['n_est'][i],learning_rate = tuning['l_rate'][i],max_depth=tuning['max_depth'][i])\n",
        "    #print(model)\n",
        "    print(model)\n",
        "    print(tuning['n_est'][i])\n",
        "    model.fit(X_important_train,y_train)\n",
        "    pred.append(predict(X_important_test,y_test))\"\"\"\n",
        "i = 1\n",
        "model = XGBClassifier(n_estimators = tuning['n_est'][i],learning_rate = tuning['l_rate'][i],max_depth=tuning['max_depth'][i])\n",
        "model.fit(X_important_train,y_train)\n",
        "y_pred_test = model.predict(X_important_test)\n",
        "#print(y_pred_test)\n",
        "con_matrix = confusion_matrix(y_pred_test, y_test)\n",
        "print(con_matrix)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'n_est'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-67-c45a02677476>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     pred.append(predict(X_important_test,y_test))\"\"\"\n\u001b[0;32m     21\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuning\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'n_est'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuning\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'l_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtuning\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_important_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_important_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'n_est'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkHcO9MhHGna",
        "colab_type": "code",
        "colab": {},
        "outputId": "b826bac2-45c5-4e23-82cd-6463a637862e"
      },
      "source": [
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.metrics import accuracy_score, make_scorer\n",
        "# Define our search space for grid search\n",
        "search_space = [\n",
        "  {\n",
        "    'clf__n_estimators': [50, 100, 150, 200],\n",
        "    'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'clf__max_depth': range(3, 10),\n",
        "    'clf__colsample_bytree': [i/10.0 for i in range(1, 3)],\n",
        "    'clf__gamma': [i/10.0 for i in range(3)],\n",
        "    'fs__score_func': [chi2],\n",
        "    'fs__k': [10],\n",
        "  }\n",
        "]\n",
        "# Define cross validation\n",
        "kfold = KFold(n_splits=10, random_state=42)\n",
        "# AUC and accuracy as score\n",
        "scoring = {'AUC':'roc_auc', 'Accuracy':make_scorer(accuracy_score)}\n",
        "# Define grid search\n",
        "grid = GridSearchCV(\n",
        "  pipe,\n",
        "  param_grid=search_space,\n",
        "  cv=kfold,\n",
        "  scoring=scoring,\n",
        "  refit='AUC',\n",
        "  verbose=1,\n",
        "  n_jobs=-1\n",
        ")\n",
        "# Fit grid search\n",
        "model = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipe' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-68-5f91454050ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Define grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m grid = GridSearchCV(\n\u001b[1;32m---> 22\u001b[1;33m   \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m   \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjpu9mvAHGnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ahew8LgBkYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "con_matrix = confusion_matrix(y_pred_train_model_1, y_train)\n",
        "\n",
        "tp, fp, fn, tn = con_matrix.ravel()\n",
        "\n",
        "print(con_matrix)\n",
        "print(tp, fp, fn, tn)\n",
        "precision = tp/(tp+fp)\n",
        "print(\"precision = \", precision)\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print(\"recall = \", recall)\n",
        "\n",
        "f1 = (2*recall*precision)/(recall+precision)\n",
        "print(\"f1 = \",f1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvpgHFOBHGng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}